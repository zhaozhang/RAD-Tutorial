{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0636469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a1dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch1/00946/zzhang/python-envs/venv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/scratch1/00946/zzhang/python-envs/venv/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37c4ec",
   "metadata": {},
   "source": [
    "## 1. Read the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cd3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, DEVICE):\n",
    "  checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "  return checkpoint\n",
    "\n",
    "def load_model_fm_checkpoint(checkpoint, primitive_model, DEVICE):\n",
    "  primitive_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  return primitive_model.to(DEVICE)\n",
    "\n",
    "def getVGGModel():\n",
    "  vgg16 = models.vgg16_bn(weights=models.vgg.VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "\n",
    "  # Fix the conv layers parameters\n",
    "  for conv_param in vgg16.features.parameters():\n",
    "    conv_param.require_grad = False\n",
    "\n",
    "  # Replace w/ new classification layers\n",
    "  classifications = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(25088,1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(1024,3)\n",
    "  )\n",
    "\n",
    "  vgg16.classifier = classifications\n",
    "\n",
    "  return vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efa7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_dump_dir = \"./output_model/best_model.pt\"\n",
    "model = None\n",
    "\n",
    "try:\n",
    "    ckpt = load_checkpoint(model_dump_dir, DEVICE)\n",
    "    model = load_model_fm_checkpoint(ckpt, getVGGModel(), DEVICE)\n",
    "except FileNotFoundError: \n",
    "    print(f\"{model_dump_dir} does not exist, please first train the model before performing inference!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca092c",
   "metadata": {},
   "source": [
    "## 2. Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40889a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_datasets(test_path):\n",
    "  img_transform = transforms.Compose([transforms.Resize((244,244)),transforms.ToTensor()])\n",
    "  try:\n",
    "    test_dataset = datasets.ImageFolder(test_path, transform=img_transform) \n",
    "  except:\n",
    "    print(f\"test_path: {test_path} does not exist!\")\n",
    "  print(f\"Test set size: {len(test_dataset)}\")\n",
    "  return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb162196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the path to train, cross_validation, and test images below:\n",
    "test_path = \"/tmp/Dataset_2/Validation/\"\n",
    "test_set = load_test_datasets(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc90c3",
   "metadata": {},
   "source": [
    "## 3. Perform inference on a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = torch.randint(0, len(test_set), size=(1,1))\n",
    "sample_image, label = test_set[random_idx]\n",
    "plt.imshow(sample_image.permute(1,2,0))\n",
    "plt.show()\n",
    "print(f\"label: {label} for image_idx: {random_idx}\")\n",
    "\n",
    "sample = sample_image.unsqueeze(0).to(DEVICE)\n",
    "prediction = torch.argmax(model(sample))\n",
    "print(f\"prediction result: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629805d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff52c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
